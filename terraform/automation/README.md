To setup Terraform project, please follow below instructions.

1: Install Terraform
1: Confirm we have the packages wget & unzip installed.
For Red Hat / CentOS, Run the below:

yum install wget unzip
For Ubuntu / Debian

apt-get install wget unzip
For MacOS

brew install wget unzip
2: Download terraform binary
First visit the terraform download page using the link:https://releases.hashicorp.com/terraform/0.11.14/

Checkout for your prefer OS and Arch (32-bit / 64-bit) and Simply right click on the 32-bit / 64-bit option and select the "Copy Link Address".



Open Termial , enter the command wget followed by a space and then paste the copied link there, and press enter. This will download terraform binary in zip format directly to the server.

wget <COPIED LINK>


For Eg: For MacOS


wget https://releases.hashicorp.com/terraform/0.12.1/terraform_0.12.1_darwin_amd64.zip
3: Extract the zip file.
Run below command to extract the zip file. You get binary file named "terraform" after extraction.

unzip terraform*

5: Move terraform binary to /usr/local/bin/.

Move binary file from Step 4, to /usr/local/bin

mv terraform /usr/local/bin/
6: Confirm the installation
Confirm the terraform installation by executing the terraform command, It should show version as "Terraform v0.11.14".

# terraform --version

Terraform v0.11.14
2: Install AWS CLI
a: Using homebrew on your mac:
1. Install awscli using brew
$ brew install awscli
2. Give permissions to pkgconfig
$ chmod 755 /usr/local/lib/pkgconfig
3. If you get below warning
Warning: awscli 1.14.30 is already installed, it's just not linked.You can use `brew link awscli` to link this version.
4. Link your awscli
$ brew link awscli
5. Check if it is working
$aws 
usage: aws [options] <command> <subcommand> [<subcommand> ...] [parameters]
To see help text, you can run:
aws help
aws <command> help
aws <command> <subcommand> help
b: Using pip on your mac:
Please follow instruction give in below link to install aws-cli on your MacOS using pip.

https://docs.aws.amazon.com/cli/latest/userguide/install-macos.html#awscli-install-osx-pip

3: Create separate AWS Organization
Every environment should have separate AWS account. This is achieved by creating multiple AWS organizations under root AWS account. Please follow the steps provided in below link to create a organization.

https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts_create.html

4: Create IAM User
Once the Organization is created, create a IAM user with administrative access. Follow the below steps.

To create an IAM group and attach policies (console)

Sign in to the AWS Management Console created in Step 3 and open the IAM console at https://console.aws.amazon.com/iam/.

In the navigation pane, click Groups and then click Create New Group.

In the Group Name box, type the name Administrators of the group and then click Next Step.

In the list of policies, select the policy AdministratorAccess check box . Then click Next Step.

Click Create Group.

To create  IAM users (console)

Sign in to the AWS Management Console created in Step 3 and open the IAM console at https://console.aws.amazon.com/iam/.

In the navigation pane, choose Users and then choose Add user.

Type the user name for the new user. This is the sign-in name for AWS.

Select the below type of access this set of users will have.

Select Programmatic access if the users require access to the API, AWS CLI, or Tools for Windows PowerShell. This creates an access key for each new user. You can view or download the access keys when you get to the Final page.

Select AWS Management Console access if the users require access to the AWS Management Console. This creates a password for each new user.

For Console password, choose one of the following:

Autogenerated password. Each user gets a randomly generated password that meets the account password policy in effect (if any). You can view or download the passwords when you get to the Finalpage.

Custom password. Each user is assigned the password that you type in the box.

We recommend that you select Require password reset to ensure that users are forced to change their password the first time they sign in.

Choose Next: Permissions.

On the Set permissions page, specify how you want to assign permissions to this set of new users. Choose one of the following three options:

Add user to group. Choose this option and add user to Administrators group created earlier

(Optional) Skip Set a permissions boundary.

Choose Next: Tags.

(Optional) Add metadata to the user by attaching tags as key-value pairs.

Choose Next: Review to see all of the choices you made up to this point. When you are ready to proceed, choose Create user.

To view the users' access keys (access key IDs and secret access keys), choose Show next to each password and access key that you want to see. To save the access keys, choose Download .csv and then save the file to a safe location.

5. Configure AWS credentials using aws-cli
After creating IAM user in Step 4, create a credential profile which will be used to run terraform script.

Below command asks for Access Key ID and Secret Access Key of the IAM user you created in Step 4

$ aws configure --profile <PROFILE_NAME>
AWS Access Key ID [None]: <ACCESS KEY ID OF IAM USER FROM Step 4>
AWS Secret Access Key [None]: <SECRET ACCESS KEY ID OF IAM USER FROM Step 4>
Default region name [None]: <DEFAULT REGION NAME WHERE YOU WANT TO CREATE TF RESOURCES>
Default output format [None]: <ENTER>
You can check the credentials in file

~/.aws/credentials and ~/.aws/config

This is important step in the process of running Terraform script.

6. Clone Terraform scripts from Git Repo.
Clone the terraform scripts from git repo.

git clone <git-repo.git>
Change to 

$ cd infrastructure/automation
automation$ ls 
certs   example modules
automation$ 
7. Create Environment folder
As per the best practice, one should create separate folders for separate envs like for qa, prod, test, beta etc.

So create a folder based on env name.  

For documentation purpose we are using environment as "qa". You should use respective environment name.


If prod, then

automation$ mkdir prod
If qa, then

automation$ mkdir qa
If beta, then

automation$ mkdir beta
etc.



8. Copy files from example
Copy all the files and folder available in example folder to env folder.

If prod, then

automation$ cp -r example/* prod/
If qa, then

automation$ cp -r example/* qa/
If beta, then

automation$ cp -r example/* beta/
etc.

And change  directory to specific env. 

automation$ cd qa
qa$ ls
alb.tf        cloudwatch.tf ec2.tf        inventory     main.tf       provider.tf   script.sh     templates

backend.tf    db.tf         iam.tf        inventory.tf  outputs.tf    redis.tf      sg.tf         variables.tf
9. Create S3 bucket for remote state
When working with Terraform as a team, it is always ideal to set up a remote state as multiple people want to update the same state file. We are going to use S3 to save remote state of  terraform.

What is Remote State?

Take a look at https://www.terraform.io/docs/state/remote.html



Sign in to the AWS Management Console created in Step 3console at https://console.aws.amazon.com/iam/.

Under Storage & Content Delivery, choose S3 to open the Amazon S3 console.

From the Amazon S3 console dashboard, choose Create Bucket.

In Create a Bucket, type a bucket name in <Bucket Name>.

In Region, choose Respective Region.

Choose Create.

When Amazon S3 successfully creates your bucket, the console displays your empty bucket in the Buckets pane.

Go to the Buckets pane, In the Bucket name list, choose the Bucket name just created.
Choose Create folder.
Type a name for the folder as qa-terraform-states  then choose Save. Change the environment when necessary.


10. Set remote state for terraform project.
Now you have created a S3 bucket to save terraform state remotely, add the S3 details in below to take the effect.

Open backend.tf in your favorite editor, here I am using vi

qa$ vi backend.tf
Replace the values which from earlier steps

terraform {
  backend "s3" {
    bucket = "< BUCKET NAME FROM STEP 9 >"
    key    = "<FOLDER_NAME_Step_9.9>/terraform.tfstate"
    region = "< AWS REGION WHERE BUCKET IS CREATED >"
    profile = "< AWS PROFILE NAME CREATED in STEP 5>"
  }
}
Save and quit file.

Now Run below command to initialize remote state setup.

qa$ terraform init



Initializing modules...
- module.main-alb
- module.master_db
- module.replica
- module.app-ec2
- module.worker-ec2
- module.mgt-ec2
- module.main-vpc
- module.ec-redis-jobs
- module.ec-redis-cache
- module.main-sg

Initializing the backend...

Successfully configured the backend "s3"! Terraform will automatically
use this backend unless the backend configuration changes.

Initializing provider plugins...

The following providers do not have any version constraints in configuration,
so the latest version was installed.

To prevent automatic upgrades to new major versions that may contain breaking
changes, it is recommended to add version = "..." constraints to the
corresponding provider blocks in configuration, with the constraint strings
suggested below.

* provider.aws: version = "~> 2.13"
* provider.null: version = "~> 2.1"
* provider.random: version = "~> 2.1"
* provider.template: version = "~> 2.1"

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
Above command installs all the modules required to run the terraform scripts.

11: Change the database template
You will find the 3 templates for database.yml , redis.yml and redis-jobs.yml under templates folder.

qa$ ls templates
database.yml.tpl   redis-jobs.yml.tpl redis.yml.tpl
Assign the variable DB_NAME in front of required environment database name.

1: Open database..yml

qa$ cd templates
templates$ vi database.yml
And assign value as per the environment. 

For prod:

default: &default
  adapter: mysql2
  host: ${DB_HOST}
  port: 3306
  username: ${DB_USER}
  password: ${DB_PASSWORD}
  encoding: utf8
  pool: 5
  timeout: 5000

development:
  <<: *default
  database: ""

staging:
  <<: *default
  database: ""

beta:
  <<: *default
  database: ""

qa:
  <<: *default
  database: ""

production:
  <<: *default
  database: ${DB_NAME}

For qa:

default: &default
  adapter: mysql2
  host: ${DB_HOST}
  port: 3306
  username: ${DB_USER}
  password: ${DB_PASSWORD}
  encoding: utf8
  pool: 5
  timeout: 5000

development:
  <<: *default
  database: ""

staging:
  <<: *default
  database: ""

beta:
  <<: *default
  database: ""

qa:
  <<: *default
  database: ${DB_NAME}

production:
  <<: *default
  database: ""
Save and quit.

12: Provider Configuration
Provider offers a set of named resource types, and defines for each resource type which arguments it accepts, which attributes it exports, and how changes to resources of that type are actually applied to remote APIs.

We are using AWS provider to create required resources. To create provider configuration follow the below steps.

1: Create provider.tf file.

qa$ touch provider.tf
2: Open provider.tf 

qa$ vi provider.tf
3: Add below contents in provider.tf

provider "aws" {
  region = "${var.AWS_REGION}"
  profile = "< PROFILE NAME CREATED IN Step 5 >"
}
4: Save and quit.

13: Copy SSL certificates.
Terraform projects uses ssl certificates to enable https routing and assigns it to Load Balancer. Defaults are self-signed certificates which are available in certs/ folder.

$ cd infrastructure/automation
automation$ ls 
certs   example modules
automation$ cd certs
certs$ ls
server.crt server.csr server.key
To use signed certificates, copy your certificate files in certs/ directory

$ cd infrastructure/automation
automation$ cp < path_of_signed_crt_file > certs/server.crt
automation$ cp < path_of_signed_key_file > certs/server.key
14: Create ssh key files
When you create an instance on AWS, ssh key files are necessary to connect to it. You can provide ssh keys to Terraform, which will be used in instance creation process.

Follow the below process to create ssh key files.

1: Enter the following command. This starts the key generation process. When you execute this command, the ssh-keygen utility prompts you to indicate where to store the key.

$ ssh-keygent -t rsa
2: Press the ENTER key to accept the default location or pass key file name.

$ ssh-keygen -t rsa
Generating public/private rsa key pair.
Enter file in which to save the key (/Users/test/.ssh/id_rsa): qa_aws_tf_id_rsa
3:  The ssh-keygen utility prompts you for a passphrase. Type in a passphrase. You can also hit the ENTER key to accept the default (no passphrase). You will need to enter the passphrase a second time to continue.

$ ssh-keygen -t rsa
Generating public/private rsa key pair.
Enter file in which to save the key (/Users/test/.ssh/id_rsa): qa_aws_tf_id_rsa
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
4: After you confirm the passphrase, the system generates the key pair and you will see output like this:

Your identification has been saved in qa_aws_tf_id_rsa.
Your public key has been saved in qa_aws_tf_id_rsa.pub.
The key fingerprint is:
SHA256:QlODlvcn/lxw48HxxrAFsQ7g6lBMrD6IPFVaEqx4698 Sushil@Sushils-MacBook-Pro.local
The key's randomart image is:
+---[RSA 2048]----+

|   ... ++ .   oo |

|    o *+oo .  o..|

| . . *ooo.. ...B |

|. o o..o .o oo* +|

| o + oo S. o +.+ |

|  = . o+  .   o  |

| . .   ..  o .   |

|  .  .      o    |

|   .. E          |

+----[SHA256]-----+


15: Define variables
Terraform configurations in .tf files accept values from input variables. These variables are used in configuration using Terraformâ€™s interpolation syntax. 

Variable definitions are in variables.tf file. The variable definitions have default values assigned to them. Each variable definition has their own description.

For eg: variable "app_instance_count" in below block has default value as "1".

variable "app_instance_count" {
  description = "Number of instances to launch"
  default     = 1
}
The variables which don't have default values, TF expects values to be entered while running terraform commands like plan or apply. 

So one way is to populate variable values via files, does allow persistence. When Terraform runs it will look for a file called terraform.tfvars. We can populate this file with variable values that will be loaded when Terraform runs.

1: Create terraform.tfvars file.

qa$ touch terraform.tfvars
When Terraform runs it will automatically load the terraform.tfvars file and assign any variable values in it.

2: Populate the variables which don't have default values. Below is the list of variables which are needed to run the terraform scripts. For more description, please refer variables.tf file.

Open terraform.tfvars

qa$ vi terraform.tfvars
Below is the list of variables which should be defined before running the terraform commands.

name = ""


AWS_REGION = ""


tags = {
	Terraform = true
	Environment = ""
}

app_ami = "< APP BASE IMAGE ID>"
worker_ami = "< WORKER BASE IMAGE ID >"
mgt_ami = "<MGT BASE IMAGE ID>"

app_instance_count = 
worker_instance_count = 
mgt_instance_count = 

app_instance_type = 
worker_instance_type = 
mgt_instance_type = 

create_new_key_pair = true
ssh_key_filename = "<.pub KEY GENERATED IN Step 14>"
ssh_key_pair_name = ""


enable_nat_gateway = "true"

app_root_volume_size = 20
worker_root_volume_size = 20
mgt_root_volume_size = 20

app_data_volume_size = 20
worker_data_volume_size = 20
mgt_data_volume_size = 20



database_name = ""
database_user = ""
database_passwd = ""

master_db_identifier = ""
replica_db_identifier = ""

redis_jobs_node_count = 
redis_jobs_node_type = ""

redis_cache_node_count = 
redis_cache_node_type = ""


enable_https = 
cert_crt_file_path = "../certs/server.crt"
cert_key_file_path = "../certs/server.key"


enable_cloudwatch = 


For default values , please refer to variables.tf file. It has description of all the variables. You can override the default value of any variable, by adding in it terraform.tfvars file.

16: Run Terraform Commands
 Once you are through with all above steps, its time to create infrastructure. Please follow below steps.

1: Initialize 
command is used to initialize a working directory containing Terraform configuration files.

qa$
terraform init
2: Plan
Run Terraform plan . The terraform plan command is used to create an execution plan. Terraform performs a refresh, unless explicitly disabled, and then determines what actions are necessary to achieve the desired state specified in the configuration files.

This command is a convenient way to check whether the execution plan for a set of changes matches your expectations without making any changes to real resources or to the state.

qa$ terraform plan
3: Apply
command is used to apply the changes required to reach the desired state of the configuration, or the pre-determined set of actions generated by a terraform plan execution plan.

qa$ terraform apply
17: Copy ymls on Management instance
After infrastructure is ready, Terraform creates yml files under inventory/ directory. These files are used in Capistrano deployment. To make these file available to Capistrano, you have to copy ymls on Managament instance. To copy, use below commands

1: Get the IP of Management server

Run terraform output which gives you Management IP address. 

qa$ terraform output mgt_public_ip_address
54.69.23.161


2: Once you get the management server IP, use private key generated in Step 14 to connect using SSH. 

qa$ scp -i <path-of-private-key-generated-in-step-14> inventory/*.ymls ubuntu@<management_server_ip_from_above_command>:/tmp/
This will copy all ymls on management server under /tmp folder.

18: Copy inventory on Management instance
Terraform also creates inventory file which contains host-ip details of app and worker instances. The contents looks like

qa$ cat inventory/inventory 

10.0.1.79                     	 qa.app1.nfg.org
10.0.2.14                     	 qa.app2.nfg.org
10.0.1.202                    	 qa.app3.nfg.org
10.0.2.62                     	 qa.app4.nfg.org
10.0.10.52                    	 qa.worker1.nfg.org
10.0.11.156                   	 qa.worker2.nfg.org
Copy these contents in /etc/hosts on Management server.

1: First connect to Management server

qa$ ssh -i <path-of-private-key-generated-in-step-14> ubuntu@<management-server-ip>
2: Open /etc/hosts and copy contents.

<management-server-ip>$ sudo vi /etc/hosts


Append inventory contents 
3: Save and quit.

19: Add users to SNS notification topic
Terraform does not support authorization of email ids  because the endpoint needs to be authorized and does not generate an ARN until the target email address has been validated. This breaks the Terraform model and as a result are not currently supported.

So adding email ids to SNS topic for cloudwatch monitoring should be manual.

1: Find the topic name
Get the topic details from below command

qa$ terraform output cw_notification_group
2: Please follow below steps to add users to SNS topics.
Sign in to the AWS Management Console created in Step 3 console at https://console.aws.amazon.com/.

On the navigation panel, choose Subscriptions.

On the Subscriptions page, choose Create subscription.

On the Create subscription page, do the following:

Enter the Topic ARN of the topic created earlier from Step 19.1.

For Protocol, select an endpoint type, for example Email.

For Endpoint, enter an email address that can receive notifications, for example:

name@example.com
Note

After your subscription is created, you must confirm it. 

Choose Create subscription.

The subscription is created and the Subscription: 1234a567-bc89-012d-3e45-6fg7h890123i page is displayed.

The subscription's ARN, Endpoint, Topic, Status (Pending confirmation at this stage), and Protocol are displayed in the Details section.

In your email client, check the email address that you specified and choose Confirm subscription in the email from Amazon SNS.

In your web browser, a subscription confirmation with your subscription ID is displayed.


